<!doctype html>
<html lang="zh-CN">
 <head>
  <meta charset="utf-8">
  <link rel="canonical" href="https://blog.csdn.net/wangkaidehao/article/details/105507809">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="report" content="{&quot;pid&quot;: &quot;blog&quot;, &quot;spm&quot;:&quot;1001.2101&quot;}">
  <meta name="referrer" content="always">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <link rel="alternate" media="handheld" href="#">
  <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
  <meta name="applicable-device" content="pc">
  <link href="https://g.csdnimg.cn/static/logo/favicon32.ico" rel="shortcut icon" type="image/x-icon">
  <title>MAML复现全部细节和经验教训（Pytorch）-CSDN博客</title>
  <meta name="keywords" content="maml复现">
  <meta name="csdn-baidu-search" content="{&quot;autorun&quot;:true,&quot;install&quot;:true,&quot;keyword&quot;:&quot;maml复现&quot;}">
  <meta name="description" content="文章浏览阅读1.4w次，点赞41次，收藏131次。我将在本文分享我复现maml时的经验和教训。_maml复现">
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-38ddee24dc.min.css">
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin3-template/skin3-template-762f7595fd.min.css">
  <meta name="toolbar" content="{&quot;type&quot;:&quot;0&quot;,&quot;fixModel&quot;:&quot;1&quot;}">
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css">
  <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
 </head>
 <body class="nodata " style="">
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css">
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css">
  <link rel="stylesheet" href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css"><div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;"><div class="container clearfix container-concision" id="mainBox">
    <main>
     <div class="blog-content-box"><div class="article-header-box"><div class="article-header"><div class="article-title-box">
         <h1 class="title-article" id="articleContentId">MAML复现全部细节和经验教训（Pytorch）</h1></div><div class="article-info-box"><div class="article-bar-top"><img class="article-type-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png" alt=""><div class="bar-content"><img class="article-vip-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/identityVip.png" alt=""> <span class="article-vip-text vip_article"> VIP文章</span> <a class="follow-nickName " href="https://blog.csdn.net/wangkaidehao" target="_blank" rel="noopener" title="miguemath">miguemath</a> <img class="article-time-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png" alt=""> <span class="time">于&nbsp;2020-04-14 11:17:49&nbsp;发布</span>
           <div class="read-count-box"><img class="article-read-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/articleReadEyes2.png" alt=""> <span class="read-count">阅读量1.4w</span> <a id="blog_detail_zk_collection" class="un-collection" data-report-click="{&quot;mod&quot;:&quot;popu_823&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" alt=""> <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" alt=""> <span class="name">收藏</span> <span class="get-collection"> 131 </span> </a>
            <div class="read-count-box is-like"><img class="article-read-img article-heard-img" style="display:none" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" alt=""> <img class="article-read-img article-heard-img" style="display:block" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" alt=""> <span class="read-count" id="blog-digg-num">点赞数 41 </span></div></div></div></div><div class="blog-tags-box"><div class="tags-box artic-tag-box"><span class="label">分类专栏：</span> <a class="tag-link" href="https://blog.csdn.net/wangkaidehao/category_9703791.html" target="_blank" rel="noopener">Pytorch</a> <span class="label">文章标签：</span> <a rel="nofollow" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;深度学习&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;深度学习\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank">深度学习</a> <a rel="nofollow" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;人工智能&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;人工智能\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank">人工智能</a> <a rel="nofollow" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;元学习&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;元学习\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E5%85%83%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank">元学习</a> <a rel="nofollow" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;pytorch&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;pytorch\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=pytorch&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank">pytorch</a> <a rel="nofollow" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;机器学习&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;机器学习\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=" target="_blank">机器学习</a></div></div><div class="slide-content-box"><div class="article-copyright"><div class="creativecommons">
            版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。</div><div class="article-source-link">
            本文链接：<a href="https://blog.csdn.net/wangkaidehao/article/details/105507809" target="_blank">https://blog.csdn.net/wangkaidehao/article/details/105507809</a></div></div></div><div class="operating"><a class="href-article-edit slide-toggle">版权</a></div></div></div></div><div id="blogHuaweiyunAdvert"></div>
      <article class="baidu_pl"><div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-044f2cf1dc.css"><div id="content_views" class="markdown_views prism-github-gist">
         <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
         </svg>
         <p>由于MAML作者提供的源码比较混乱，而且是由tensorflow写成。所以我写了一篇用Pytorch复现MAML的博客：<a href="https://blog.csdn.net/wangkaidehao/article/details/104597626">MAML模型无关的元学习代码完整复现（Pytorch版）</a>。那篇博客中的复现细节已经很详尽了，但是在omniglot数据集上的准确率只有0.92，考虑到omniglot算是比较简单的数据集了，因此0.92的准确率实在是太低了。</p>
         <p>因此，我后来又对模型和数据的读取方法进行了一些调整，最近的实验表明在5-way-1-shot任务上，我的复现准确率已经达到了0.972，算是基本匹配上了作者在论文中给出的准确率区间。</p>
         <p>在这篇文章中，我将总结一下我复现MAML时的一些经验和教训以及对原来代码的更改。</p>
         <h3><a id="1__6"></a>1 数据读取方式</h3>
         <p>我之前的数据读取方式是将omniglot中images_backgroud和images_evaluation这两个文件夹中的数据一次性读取出来，然后再对数据集进行划分。</p>
         <pre class="set-code-show"><code class="prism language-python">img_list <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> <span class="token string">'omniglot.npy'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (1623, 20, 1, 28, 28)</span>
x_train <span class="token operator">=</span> img_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1200</span><span class="token punctuation">]</span>
x_test <span class="token operator">=</span> img_list<span class="token punctuation">[</span><span class="token number">1200</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
</code></pre>
         <p>这一次我使用通用的数据划分方法，即：images_backgroud中的数据作为训练数据，images_evaluation中的数据作为测试数据。</p>
         <pre class="set-code-show"><code class="prism language-python">img_list_train <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> <span class="token string">'omniglot_train.npy'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (964, 20, 1, 28, 28)</span>
img_list_test <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span> <span class="token string">'omniglot_test.npy'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># (659, 20, 1, 28, 28)</span>

x_train <span class="token operator">=</span> img_list_train
x_test <span class="token operator">=</span> img_list_test
</code></pre>
         <p>具体代码见我的<a href="https://github.com/miguealanmath/MAML-Pytorch">github</a>。</p>
         <h3><a id="2__28"></a>2 模型构造</h3>
         <p>原来的模型卷积层的padding为2，stride也为2；我将它们修改为1之后，实验结果直接从0.92提升到了0.975。由此可见模型架构的微小调整也会严重影响模型的性能。大家平时在做实验时应该注意一下。</p>
         <p>原来的模型架构为：</p>
         <pre class="set-code-show"><code class="prism language-python"><span class="token comment">#         self.conv = nn.Sequential(</span>
<span class="token comment">#             nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = (3,3), padding = 2, stride = 2),</span>
<span class="token comment">#             nn.BatchNorm2d(64),</span>
<span class="token comment">#             nn.ReLU(),</span>
<span class="token comment">#             nn.MaxPool2d(2),</span>
            
<span class="token comment">#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 2, stride = 2),</span>
<span class="token comment">#             nn.BatchNorm2d(64),</span>
<span class="token comment">#             nn.ReLU(),</span>
<span class="token comment">#             nn.MaxPool2d(2),</span>
            
<span class="token comment">#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 2, stride = 2),</span>
<span class="token comment">#             nn.BatchNorm2d(64),</span>
<span class="token comment">#             nn.ReLU(),</span>
<span class="token comment">#             nn.MaxPool2d(2), </span>
            
<span class="token comment">#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 2, stride = 2),</span>
<span class="token comment">#             nn.BatchNorm2d(64),</span>
<span class="token comment">#             nn.ReLU(),</span>
<span class="token comment">#             nn.MaxPool2d(2), </span>
            
<span class="token comment">#             FlattenLayer(),</span>
<span class="token comment">#             nn.Linear(64,5)</span>
<span class="token comment">#         )   </span>
</code></pre>
         <p>修改后的模型架构为：</p>
         <pre class="set-code-show"><code>#         self.conv = nn.Sequential(
#             nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = (3,3), padding = 1, stride = 1),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
            
#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 1, stride = 1),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),
#             nn.MaxPool2d(2),
            
#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 1, stride = 1),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),
#             nn.MaxPool2d(2), 
            
#             nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding = 1, stride = 1),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),
#             nn.MaxPool2d(2), 
            
#             FlattenLayer(),
#             nn.Linear(64,5)
#         )   
</code></pre>
         <h3><a id="3__90"></a>3 降低对计算资源的要求</h3>
         <p>在进行20-way-1-shot的实验时，发现用原来的代码将会消耗大量的资源。我修改了一下原来的代码，在不需要记录梯度的位置加上"with torch.no_grad()"，从而将计算资源的需求降到了原来的1/5.</p>
         <p>原来的代码为：</p>
         <pre class="set-code-show"><code class="prism language-python">            <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_step<span class="token punctuation">)</span><span class="token punctuation">:</span>
                
                y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x_spt<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> params <span class="token operator">=</span> fast_weights<span class="token punctuation">,</span> bn_training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_spt<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> fast_weights<span class="token punctuation">)</span>
                tuples <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>grad<span class="token punctuation">,</span> fast_weights<span class="token punctuation">)</span> 
                fast_weights <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> p<span class="token punctuation">:</span> p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>base_lr <span class="token operator">*</span> p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tuples<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    
                y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> params <span class="token operator">=</span> fast_weights<span class="token punctuation">,</span> bn_training <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
                loss_qry <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                loss_list_qry<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> loss_qry
                
                <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    pred_qry <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
                    correct <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred_qry<span class="token punctuation">,</span> y_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    correct_list<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> correct
</code></pre>
         <p>修改后的代码为：</p>
         <pre class="set-code-show"><code class="prism language-python">            <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_step<span class="token punctuation">)</span><span class="token punctuation">:</span>
                
                y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x_spt<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> params <span class="token operator">=</span> fast_weights<span class="token punctuation">,</span> bn_training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_spt<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> fast_weights<span class="token punctuation">)</span>
                tuples <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>grad<span class="token punctuation">,</span> fast_weights<span class="token punctuation">)</span> 
                fast_weights <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> p<span class="token punctuation">:</span> p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>base_lr <span class="token operator">*</span> p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tuples<span class="token punctuation">)</span><span class="token punctuation">)</span>
                
                <span class="token keyword">if</span> k <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>update_step <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        
                        y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> params <span class="token operator">=</span> fast_weights<span class="token punctuation">,</span> bn_training <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
                        loss_qry <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        loss_list_qry<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> loss_qry
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                        y_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> params <span class="token operator">=</span> fast_weights<span class="token punctuation">,</span> bn_training <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
                        loss_qry <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        loss_list_qry<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> loss_qry                    
                
                <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    pred_qry <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
                    correct <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred_qry<span class="token punctuation">,</span> y_qry<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    correct_list<span class="token punctuation">[</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> correct
</code></pre>
         <h3><a id="4_20way1shot_141"></a>4 关于20-way-1-shot实验</h3>
         <p><strong>2020/5/10更新：</strong></p>
         <p><strong>Reptile这篇论文中说，MAML的实验使用到了transductive Learning的实验设定。关于transductive Learning你可以理解成MAML作者汇报的是训练中query集的结果，而不是我们通常意义的测试集中query集的结果。</strong><br> <strong>这个图表来自Reptile的那篇论文。</strong><br> <img src="https://img-blog.csdnimg.cn/2020051018374260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmdrYWlkZWhhbw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>以下是原文：</strong></p>
         <hr>
         <p>我在复现这个实验的过程中，在测试集的query集中的最好结果也只有0.843。但是作者宣称她取得了0.95的实验结果，但是作者的源码中并没有给出20-way-1-shot的实验结果或者logs。</p>
         <p>我找到了另一个网友（github账号名：<a href="https://github.com/katerakelly/pytorch-maml">katerkelly</a>）的复现代码，这个人宣称他复现出来的结果是0.92。</p>
         <blockquote>
          <p>20-way 1-shot training, best performance 92%</p>
         </blockquote>
         <p>但是我实际运行以及查看了他的代码后发现，他报告的其实是训练集中query集的结果，而不是测试集中query集的结果。我们都知道在元学习中有support集和query集两者集合，其中:</p>
         <ul>
          <li>训练集：分为support集和query集，其中support集用于训练，query集用于更新参数。</li><li>测试集：分为support集和query集，其中support集用于fine-tune，query集用于评估元学习模型的效果。</li>
         </ul>
         <p>而那位网友报告的是训练集中support集的结果，真正的实验结果应该是测试集中support集的实验结果,也就是0.83。</p>
         <p>你可以查看那位网友给出的实验结果展示图（下图）。中间那条橙黄色的线是0.92左右，那位网友报告的也是橙黄色这条线的结果，但是实际的实验结果应该是下面这条红色的线。也就是0.83左右，跟我得出的实验结果比较吻合。<br> <img src="https://img-blog.csdnimg.cn/20200414111417867.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmdrYWlkZWhhbw==,size_16,color_FFFFFF,t_70" alt="网友的实验结果"><br> 有意思的是，MAML作者声称她的实验结果实0.95，而我自己复现的结果中，在测试集的support集上的结果也是0.95-0.96。为了跑出0.9以上的实验结果，我已经做了好几天的实验了，模型架构和超参数改动了几十次，最好的结果还是只有0.843。如果哪位网友能够复现出0.9以上的实验结果，麻烦告诉我一下。</p>
         <h3><a id="5__168"></a>5 实验数据</h3>
         <p>以下展示在60000轮epoch中，query集的测试集中出现的最好结果：</p>
         <ol>
          <li><p>20 way 1 shot 4 batch meta_lr = 0.0002, base_lr = 0.1 : acc: 0.84</p></li><li><p>20 way 1 shot 8 batch meta_lr = 0.0001, base_lr = 0.1 : acc: 0.835</p></li><li><p>20 way 1 shot 8 batch meta_lr = 0.0001, base_lr = 0.1 : acc: 0.843</p></li><li><p>20 way 1 shot 8 batch meta_lr = 0.0005, base_lr = 0.3 : acc: 0.79</p></li><li><p>20 way 1 shot 8 batch meta_lr = 0.001, base_lr = 0.1 : acc: 0.82</p></li><li><p>20 way 1 shot 8 batch meta_lr = 0.001, base_lr = 0.2 : acc: 0.785</p></li><li><p>5 way 1 shot 4 batch 10 range meta_lr = 0.001, base_lr = 0.1 : acc: 0.96</p></li><li><p>5 way 1 shot 8 batch 10 range meta_lr = 0.001, base_lr = 0.1 : acc: 0.972</p></li><li><p>5 way 1 shot 16 batch 10 range meta_lr = 0.001, base_lr = 0.1 : acc: 0.969</p></li><li><p>5 way 1 shot 32 batch 10 range meta_lr = 0.001, base_lr = 0.1 : acc: 0.975</p></li>
         </ol>
         <p>自己想要复现的朋友，可以参考一下我的实验结果，免得继续做无用功。</p>
         <h3><a id="6__190"></a>6 关于我自己的源码</h3>
         <p>你可以在我的github上找到我的全部代码（<a href="https://github.com/miguealanmath/MAML-Pytorch">miguealanmath</a>）。喜欢的朋友可以点下小星星。</p></div>
        <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-f23dff6052.css" rel="stylesheet">
        <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-c216769e99.css" rel="stylesheet"></div>
      </article></div>
    </main></div><div class="recommend-right align-items-stretch clearfix" id="rightAside" data-type="recommend"></div></div>
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/github-gist.css">
 </body>
</html>